#change permission of pem file first
chmod 400 abc.pem

#to access server via ssh
ssh -i abc.pem user@ec2-8757859vftsgjvbvbsv-ap-south-1.compute.amazonaws.com

#kill application
ec2-8757859vftsgjvbvbsv-ap-south-1.compute.amazonaws.com:8088
#Go to individual application id and kill

#spark ui port
18080

#see list of yarn applications
yarn application -list

#see list of all applications
sudo initctl list

#s3 bucket access / see
aws s3 ls s3://<bucket_name>/folder

#s3 bucket file copy / send
aws s3 cp abc.csv s3://<bucket_name>/folder

#kill yarn application using application id which is obatined from port :8088 or 18080/?showIncomplete=true
yarn application -kill application_1532556743218_0051

##Scaling/Descaling AWS servers with task nodes : First add a Task node manually from AWS GUI get its id like: ig-3VJAN33OJ9V4V
#For scaling up 
aws emr modify-instance-groups --instance-groups InstanceGroupId=ig-3VJAN33OJ9V4V,InstanceCount=10

#For scaling down/ De-scaling
aws emr modify-instance-groups --instance-groups InstanceGroupId=ig-3VJAN33OJ9V4V,InstanceCount=0

##Scaling/Descaling AWS servers' cores
Core scaling/ Descaling
aws emr modify-instance-groups --instance-groups InstanceGroupId=ig-3VJAN33OJ9V4V,InstanceCount=2

#get cluster group id from AWS UI Front end, summary
aws emr describe-cluster --cluster-id j-D56C3MBAF8VP --query 'Cluster.InstanceGroups[0].RunningInstanceCount'


###############Dealing with s3 files in pandas##########
import pandas as pd
import boto3
from io import StringIO

bucket = "yourbucket"
file_name = "your_file.csv"

s3 = boto3.client('s3') 
# 's3' is a key word. create connection to S3 using default config and all buckets within S3

obj = s3.get_object(Bucket= bucket, Key= file_name) 
# get object and file (key) from bucket
initial_df = pd.read_csv(obj['Body']) # 'Body' is a key word

csv_buffer = StringIO()
initial_df.to_csv(csv_buffer)
s3_resource = boto3.resource('s3')
resp = s3_resource.Object(bucket, 'folder/sub_folder/initial_df_file.csv').put(Body=csv_buffer.getvalue())
if resp['ResponseMetadata']['HTTPStatusCode'] == 200:
    print("All ok")
else:
    print("file not inserted in s3")

#Reference: https://stackoverflow.com/questions/43355074/read-a-csv-file-from-aws-s3-using-boto-and-pandas
#########################################################

